{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465025ce-acdd-4c27-aa16-49f74e83ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alexandra Rivera\n",
    "#Carolina Campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd822799-22b3-4650-b388-3e0f838c6874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-4.28.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio)\n",
      "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting fastapi (from gradio)\n",
      "  Downloading fastapi-0.110.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gradio-client==0.16.0 (from gradio)\n",
      "  Downloading gradio_client-0.16.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Collecting huggingface-hub>=0.19.3 (from gradio)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from gradio) (3.8.2)\n",
      "Requirement already satisfied: numpy~=1.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from gradio) (1.26.3)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.1-cp310-none-win_amd64.whl.metadata (50 kB)\n",
      "     ---------------------------------------- 0.0/50.9 kB ? eta -:--:--\n",
      "     -------------------------------- ------- 41.0/50.9 kB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 41.0/50.9 kB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 50.9/50.9 kB 437.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from gradio) (23.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from gradio) (2.7.1)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.4.2-py3-none-win_amd64.whl.metadata (24 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Collecting urllib3~=2.0 (from gradio)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from gradio-client==0.16.0->gradio) (2024.3.1)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.0->gradio)\n",
      "  Downloading websockets-11.0.3-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from httpx>=0.24.1->gradio) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from httpx>=0.24.1->gradio) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from httpx>=0.24.1->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Collecting filelock (from huggingface-hub>=0.19.3->gradio)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.4)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading referencing-0.35.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\caros\\anaconda3\\envs\\ai\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-4.28.3-py3-none-any.whl (12.2 MB)\n",
      "   ---------------------------------------- 0.0/12.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/12.2 MB 5.5 MB/s eta 0:00:03\n",
      "    --------------------------------------- 0.2/12.2 MB 2.6 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.4/12.2 MB 3.0 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.6/12.2 MB 3.0 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/12.2 MB 4.4 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.5/12.2 MB 5.3 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.5/12.2 MB 7.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.1/12.2 MB 8.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.1/12.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.4/12.2 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.4/12.2 MB 12.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.6/12.2 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.2/12.2 MB 13.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.2/12.2 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.7/12.2 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.1/12.2 MB 19.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.2/12.2 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.2/12.2 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.2/12.2 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.2/12.2 MB 16.4 MB/s eta 0:00:00\n",
      "Downloading gradio_client-0.16.0-py3-none-any.whl (314 kB)\n",
      "   ---------------------------------------- 0.0/314.4 kB ? eta -:--:--\n",
      "   --------------------------------------  307.2/314.4 kB 18.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 314.4/314.4 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "   ---------------------------------------- 0.0/857.8 kB ? eta -:--:--\n",
      "   --------------------------------------  849.9/857.8 kB 52.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  849.9/857.8 kB 52.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 857.8/857.8 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "   ---------------------------------------- 0.0/388.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 388.9/388.9 kB 12.2 MB/s eta 0:00:00\n",
      "Downloading orjson-3.10.1-cp310-none-win_amd64.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.1 kB ? eta -:--:--\n",
      "   -------------------------------------- - 133.1/139.1 kB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 133.1/139.1 kB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 139.1/139.1 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading ruff-0.4.2-py3-none-win_amd64.whl (8.5 MB)\n",
      "   ---------------------------------------- 0.0/8.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.8/8.5 MB 37.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.2/8.5 MB 40.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.0/8.5 MB 32.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.8/8.5 MB 28.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.0/8.5 MB 27.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.2/8.5 MB 25.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 27.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 25.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 25.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.5/8.5 MB 20.1 MB/s eta 0:00:00\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.2 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 41.0/47.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.2/47.2 kB 474.0 kB/s eta 0:00:00\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.8/60.8 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
      "   ---------------------------------------- 0.0/91.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 91.8/91.8 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------  71.7/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.9/71.9 kB 790.6 kB/s eta 0:00:00\n",
      "Downloading websockets-11.0.3-cp310-cp310-win_amd64.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/124.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 124.7/124.7 kB 7.2 MB/s eta 0:00:00\n",
      "Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.1 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 51.2/56.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.1/56.1 kB 588.2 kB/s eta 0:00:00\n",
      "Downloading referencing-0.35.0-py3-none-any.whl (26 kB)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py): started\n",
      "  Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5605 sha256=30ee366148c6177f9dbcec2501bc5231ea0e483898bba985c8469e89dc6d5c23\n",
      "  Stored in directory: c:\\users\\caros\\appdata\\local\\pip\\cache\\wheels\\bd\\65\\9a\\671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, urllib3, toolz, tomlkit, shellingham, semantic-version, ruff, referencing, python-multipart, orjson, filelock, aiofiles, uvicorn, starlette, typer, huggingface-hub, fastapi, gradio-client, altair, gradio\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.18\n",
      "    Uninstalling urllib3-1.26.18:\n",
      "      Successfully uninstalled urllib3-1.26.18\n",
      "  Attempting uninstall: referencing\n",
      "    Found existing installation: referencing 0.30.2\n",
      "    Uninstalling referencing-0.30.2:\n",
      "      Successfully uninstalled referencing-0.30.2\n",
      "Successfully installed aiofiles-23.2.1 altair-5.3.0 fastapi-0.110.3 ffmpy-0.3.2 filelock-3.14.0 gradio-4.28.3 gradio-client-0.16.0 huggingface-hub-0.22.2 orjson-3.10.1 pydub-0.25.1 python-multipart-0.0.9 referencing-0.33.0 ruff-0.4.2 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 toolz-0.12.1 typer-0.12.3 urllib3-2.2.0 uvicorn-0.29.0 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4961f68-e945-4528-b331-6553adb755da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import ast\n",
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f91462-1372-4e39-8b26-bb214d6def4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea6ee0c-adcb-4e8f-82c8-fe1551e193ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingChatbot():\n",
    "    def __init__(self, \n",
    "    \tembeddings_path, \n",
    "    \tmodel_embeddings = \"text-embedding-ada-002\",\n",
    "    \tmodel_completion = \"gpt-3.5-turbo-instruct\",\n",
    "    \tmax_prompt_tokens = 1200,\n",
    "    \tmax_answer_tokens = 600):\n",
    "        self.__df = pd.read_csv('embeddings_txt.csv')\n",
    "        self.__df.embeddings = self.__df.embeddings.apply(ast.literal_eval)\n",
    "        self.model_embeddings = model_embeddings\n",
    "        self.model_completion = model_completion\n",
    "        self.max_prompt_tokens = max_prompt_tokens\n",
    "        self.max_answer_tokens = max_answer_tokens \n",
    "    \n",
    "    def get_rows_sorted_by_relevance(self, question, df):\n",
    "        \"\"\"\n",
    "        Function that takes in a question string and a dataframe containing\n",
    "        rows of text and associated embeddings, and returns that dataframe\n",
    "        sorted from least to most relevant for that question\n",
    "        \"\"\"\n",
    "    \n",
    "        # Get embeddings for the question text\n",
    "        question_embeddings = get_embedding(question, engine=self.model_embeddings)\n",
    "    \n",
    "        # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "        # the cosine distances between each row's embeddings and the\n",
    "        # embeddings of the question\n",
    "        df_copy = df.copy()\n",
    "        df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        \tquestion_embeddings,\n",
    "        \tdf_copy[\"embeddings\"].values,\n",
    "        \tdistance_metric=\"cosine\"\n",
    "        \t)\n",
    "    \n",
    "        # Sort the copied dataframe by the distances and return it\n",
    "        # (shorter distance = more relevant so we sort in ascending order)\n",
    "        df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "        return df_copy\n",
    "\n",
    "\n",
    "    def create_prompt(self, question, df, max_token_count):\n",
    "        \"\"\"\n",
    "        Given a question and a dataframe containing rows of text and their\n",
    "        embeddings, return a text prompt to send to a Completion model\n",
    "        \"\"\"\n",
    "        # Create a tokenizer that is designed to align with our embeddings\n",
    "        tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "        # Count the number of tokens in the prompt template and question\n",
    "        prompt_template = \"\"\"\n",
    "        Answer the question based on the context below, and if the question\n",
    "        can't be answered based on the context, say \"I don't know\"\n",
    "        \n",
    "        Context:\n",
    "\n",
    "            {}\n",
    "        \n",
    "        ---\n",
    "\n",
    "        Question: {}\n",
    "        Answer:\"\"\"\n",
    "    \n",
    "        current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                                len(tokenizer.encode(question))\n",
    "    \n",
    "        context = []\n",
    "        for text in self.get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "        \n",
    "            # Increase the counter based on the number of tokens in this row\n",
    "            text_token_count = len(tokenizer.encode(text))\n",
    "            current_token_count += text_token_count\n",
    "        \n",
    "            # Add the row of text to the list if we haven't exceeded the max\n",
    "            if current_token_count <= max_token_count:\n",
    "                context.append(text)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)\n",
    "\n",
    "\n",
    "    def answer_question(self, question, df, max_prompt_tokens, max_answer_tokens):\n",
    "        \"\"\"\n",
    "        Given a question, a dataframe containing rows of text, and a maximum\n",
    "        number of desired tokens in the prompt and response, return the\n",
    "        answer to the question according to an OpenAI Completion model\n",
    "    \n",
    "        If the model produces an error, return an \"I do not know\"\n",
    "        \"\"\"\n",
    "\n",
    "        prompt = self.create_prompt(question, df, max_prompt_tokens)\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                model=self.model_completion,\n",
    "                prompt=prompt,\n",
    "                max_tokens=self.max_answer_tokens\n",
    "            )\n",
    "            return response[\"choices\"][0][\"text\"].strip()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return \"\"\n",
    "\n",
    "    def predict(self, question, history):\n",
    "    \treturn self.answer_question(question, self.__df, self.max_prompt_tokens, self.max_answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f4d769d-e727-4ebd-9daa-5c6912196ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = EmbeddingChatbot(\n",
    "    embeddings_path='embeddings_txt.csv',\n",
    "    model_embeddings = 'text-embedding-ada-002',\n",
    "    model_completion ='gpt-3.5-turbo-instruct',\n",
    "    max_prompt_tokens = 1800,\n",
    "    max_answer_tokens = 600\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12739c39-94ea-4a28-b7da-231b4fb3d3e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(bot.predict).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2eea7-6a25-443b-b392-9cb2b91a3934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
